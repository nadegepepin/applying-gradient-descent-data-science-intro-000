{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhFzAf/nPDwgeJNOXfz9PO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadegepepin/applying-gradient-descent-data-science-intro-000/blob/master/GloVefitCollab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6W3HfvhfEew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "2801cd87-c319-4456-abae-bc38976fc1e3"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import GloVepreprocessing\n",
        "import model\n",
        "\n",
        "\n",
        "preprocessor = GloVepreprocessing.GloVepreprocessor()\n",
        "\n",
        "X, Y  = preprocessor.batch_generator(\"train\", 0, 100)\n",
        "\n",
        "training_model,inference_initialiser_model,inference_model = model.ShowAndTell(preprocessor.MAX_SEQUENCE_LENGTH, preprocessor.VOCAB_SIZE, preprocessor.EMBEDDING_SIZE, 60, preprocessor.weights)\n",
        "\n",
        "training_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr = 0.01), metrics=['accuracy'])\n",
        "\n",
        "a0 = np.zeros((X[\"image_input\"].shape[0], 60))\n",
        "c0 = np.zeros((X[\"image_input\"].shape[0], 60))\n",
        "\n",
        "checkpoint_path = \"../data/models/checkpoints\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1)\n",
        "\n",
        "batch_size = 10\n",
        "epochs=2\n",
        "\n",
        "#tbCallback = TensorBoard(log_dir='/var/log', histogram_freq=0, write_graph=True, write_grads=False, write_images=False, update_freq='batch', embeddings_freq=0)\n",
        "\n",
        "history = training_model.fit([X[\"image_input\"],X[\"caption_input\"]\n",
        "             , a0, c0], Y[\"caption_output\"], batch_size=batch_size, epochs=epochs, verbose=2, callbacks=[cp_callback] )\n",
        "\n",
        "\n",
        "for key in history.history.keys():\n",
        "    f = plt.figure()\n",
        "    data = history.history[key]\n",
        "    plt.plot(data)\n",
        "plt.show()\n",
        "    \n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0a4326af2c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mGloVepreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'GloVepreprocessing'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}